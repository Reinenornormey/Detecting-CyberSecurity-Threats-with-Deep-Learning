{"cells":[{"source":"![cyber_photo](cyber_photo.jpg)\n\nCyber threats are a growing concern for organizations worldwide. These threats take many forms, including malware, phishing, and denial-of-service (DOS) attacks, compromising sensitive information and disrupting operations. The increasing sophistication and frequency of these attacks make it imperative for organizations to adopt advanced security measures. Traditional threat detection methods often fall short due to their inability to adapt to new and evolving threats. This is where deep learning models come into play.\n\nDeep learning models can analyze vast amounts of data and identify patterns that may not be immediately obvious to human analysts. By leveraging these models, organizations can proactively detect and mitigate cyber threats, safeguarding their sensitive information and ensuring operational continuity.\n\nAs a cybersecurity analyst, you identify and mitigate these threats. In this project, you will design and implement a deep learning model to detect cyber threats. The BETH dataset simulates real-world logs, providing a rich source of information for training and testing your model. The data has already undergone preprocessing, and we have a target label, `sus_label`, indicating whether an event is malicious (1) or benign (0).\n\nBy successfully developing this model, you will contribute to enhancing cybersecurity measures and protecting organizations from potentially devastating cyber attacks.","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"51be1f3d-e425-4d6d-9c05-fb6d98664c68","cell_type":"markdown"},{"source":"\n### The Data\n\n| Column     | Description              |\n|------------|--------------------------|\n|`processId`|The unique identifier for the process that generated the event - int64 |\n|`threadId`|ID for the thread spawning the log - int64|\n|`parentProcessId`|Label for the process spawning this log - int64|\n|`userId`|ID of user spawning the log|Numerical - int64|\n|`mountNamespace`|Mounting restrictions the process log works within - int64|\n|`argsNum`|Number of arguments passed to the event - int64|\n|`returnValue`|Value returned from the event log (usually 0) - int64|\n|`sus_label`|Binary label as suspicous event (1 is suspicious, 0 is not) - int64|\n\nMore information on the dataset: [BETH dataset](accreditation.md)","metadata":{},"id":"8811256f-f887-4867-903e-837238fbb648","cell_type":"markdown"},{"source":"# Import required libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\nfrom torchmetrics import Accuracy\n# from sklearn.metrics import accuracy_score  # uncomment to use sklearn","metadata":{"executionCancelledAt":null,"executionTime":8,"lastExecutedAt":1758803809073,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\nfrom torchmetrics import Accuracy\n# from sklearn.metrics import accuracy_score  # uncomment to use sklearn"},"id":"75892dec-9424-4c92-bf8e-2f9847b7d7cd","cell_type":"code","execution_count":27,"outputs":[]},{"source":"# Load preprocessed data\ntrain_df = pd.read_csv('labelled_train.csv')\ntest_df = pd.read_csv('labelled_test.csv')\nval_df = pd.read_csv('labelled_validation.csv')\n\n# View the first 5 rows of training set\ntrain_df.head()","metadata":{"executionCancelledAt":null,"executionTime":372,"lastExecutedAt":1758803809445,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load preprocessed data\ntrain_df = pd.read_csv('labelled_train.csv')\ntest_df = pd.read_csv('labelled_test.csv')\nval_df = pd.read_csv('labelled_validation.csv')\n\n# View the first 5 rows of training set\ntrain_df.head()","outputsMetadata":{"0":{"height":264,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"2391873d-a9c3-4f21-bc58-d01f2d5d67d3","nodeType":"const"}}}}},"id":"e52e231f-71b5-4dfc-81f9-a3321ff78047","cell_type":"code","execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"processId","type":"integer"},{"name":"threadId","type":"integer"},{"name":"parentProcessId","type":"integer"},{"name":"userId","type":"integer"},{"name":"mountNamespace","type":"integer"},{"name":"argsNum","type":"integer"},{"name":"returnValue","type":"integer"},{"name":"sus_label","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"processId":[381,381,381,7347,7347],"threadId":[7337,7337,7337,7347,7347],"parentProcessId":[1,1,1,7341,7341],"userId":[100,100,100,0,0],"mountNamespace":[4026532231,4026532231,4026532231,4026531840,4026531840],"argsNum":[5,1,0,2,4],"returnValue":[0,0,0,-2,0],"sus_label":[1,1,1,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"   processId  threadId  parentProcessId  ...  argsNum  returnValue  sus_label\n0        381      7337                1  ...        5            0          1\n1        381      7337                1  ...        1            0          1\n2        381      7337                1  ...        0            0          1\n3       7347      7347             7341  ...        2           -2          1\n4       7347      7347             7341  ...        4            0          1\n\n[5 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processId</th>\n      <th>threadId</th>\n      <th>parentProcessId</th>\n      <th>userId</th>\n      <th>mountNamespace</th>\n      <th>argsNum</th>\n      <th>returnValue</th>\n      <th>sus_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>381</td>\n      <td>7337</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>381</td>\n      <td>7337</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>381</td>\n      <td>7337</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7347</td>\n      <td>7347</td>\n      <td>7341</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>2</td>\n      <td>-2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7347</td>\n      <td>7347</td>\n      <td>7341</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":28}]},{"source":"# Start coding here\n# Use as many cells as you need","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1758803809493,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here\n# Use as many cells as you need"},"id":"6b7ee389-d5ef-4c4d-bc7a-4d0be0e1c6e1","cell_type":"code","execution_count":29,"outputs":[]},{"source":"#Separating features and labels of the training, testing and validation datasets\nx_train_df=train_df.drop(\"sus_label\",axis=1).values\ny_train_df=train_df[\"sus_label\"].values\nx_test_df=test_df.drop(\"sus_label\", axis=1).values\ny_test_df=test_df[\"sus_label\"].values\nx_val_df= val_df.drop(\"sus_label\",axis=1).values\ny_val_df= val_df[\"sus_label\"].values","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1758803809541,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Separating features and labels of the training, testing and validation datasets\nx_train_df=train_df.drop(\"sus_label\",axis=1).values\ny_train_df=train_df[\"sus_label\"].values\nx_test_df=test_df.drop(\"sus_label\", axis=1).values\ny_test_df=test_df[\"sus_label\"].values\nx_val_df= val_df.drop(\"sus_label\",axis=1).values\ny_val_df= val_df[\"sus_label\"].values"},"cell_type":"code","id":"b52ef0b2-6393-4099-944b-684455b670a5","outputs":[],"execution_count":30},{"source":"# Using Standard scaler to scale the features from 0 to 1 to ensure gradient stability\nscale=StandardScaler()\n\n#training features\nx_train_scaled=scale.fit_transform(x_train_df)\n\n#testing features\nx_test_scaled=scale.transform(x_test_df)\n\n#validation features\nx_val_scaled=scale.transform(x_val_df)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1758803809592,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Using Standard scaler to scale the features from 0 to 1 to ensure gradient stability\nscale=StandardScaler()\n\n#training features\nx_train_scaled=scale.fit_transform(x_train_df)\n\n#testing features\nx_test_scaled=scale.transform(x_test_df)\n\n#validation features\nx_val_scaled=scale.transform(x_val_df)"},"cell_type":"code","id":"e79647be-8050-4891-b0ce-1ccbab5d8115","outputs":[],"execution_count":31},{"source":"# converting the data into torch tensors\nx_train_tensor=torch.tensor(x_train_scaled,dtype=torch.float32)\ny_train_tensor=torch.tensor(y_train_df, dtype=torch.float32).view(-1,1)\nx_test_tensor=torch.tensor(x_test_scaled, dtype=torch.float32)\ny_test_tensor=torch.tensor(y_test_df, dtype=torch.float32).view(-1,1)\nx_val_tensor=torch.tensor(x_val_scaled, dtype=torch.float32)\ny_val_tensor=torch.tensor(y_val_df, dtype=torch.float32).view(-1,1)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1758803809640,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# converting the data into torch tensors\nx_train_tensor=torch.tensor(x_train_scaled,dtype=torch.float32)\ny_train_tensor=torch.tensor(y_train_df, dtype=torch.float32).view(-1,1)\nx_test_tensor=torch.tensor(x_test_scaled, dtype=torch.float32)\ny_test_tensor=torch.tensor(y_test_df, dtype=torch.float32).view(-1,1)\nx_val_tensor=torch.tensor(x_val_scaled, dtype=torch.float32)\ny_val_tensor=torch.tensor(y_val_df, dtype=torch.float32).view(-1,1)"},"cell_type":"code","id":"d4bc7b84-0d25-4433-95a8-d6d280bb50f2","outputs":[],"execution_count":32},{"source":"# defining the model layers, this is a binary classification, hence the sigmoid activation is used\nmodel=nn.Sequential(\n    nn.Linear(x_train_tensor.shape[1], 128),\n    nn.ReLU(),\n    nn.Linear(128,64),\n    nn.ReLU(),\n    nn.Linear(64,1),\n    nn.Sigmoid()\n)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1758803809688,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# defining the model layers, this is a binary classification, hence the sigmoid activation is used\nmodel=nn.Sequential(\n    nn.Linear(x_train_tensor.shape[1], 128),\n    nn.ReLU(),\n    nn.Linear(128,64),\n    nn.ReLU(),\n    nn.Linear(64,1),\n    nn.Sigmoid()\n)"},"cell_type":"code","id":"dee7bf50-a034-4949-b2e2-e0d7d79f161b","outputs":[],"execution_count":33},{"source":"# Initialising the loss function and the optimiser\ncriterion = nn.CrossEntropyLoss()\noptimizer=optim.SGD(model.parameters(), lr=0.001, momentum=0.97)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1758803809741,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialising the loss function and the optimiser\ncriterion = nn.CrossEntropyLoss()\noptimizer=optim.SGD(model.parameters(), lr=0.001, momentum=0.97)"},"cell_type":"code","id":"ed4b3de4-e0c2-4a98-8900-e0692c902c3c","outputs":[],"execution_count":34},{"source":"# Training loop \nnum_epoch=10\nfor epoch in range (num_epoch):\n    model.train()    # for training the model\n    optimizer.zero_grad()    # making the gradient zero for the start\n    outputs = model(x_train_tensor)     # Forward pass: compute the output of the model\n    loss = criterion(outputs, y_train_tensor)    # the difference between the predicted and observed y value\n    loss.backward()    # Backward pass to compute new gradients for the layers. Computes the contribution of each parameter to the loss\n    optimizer.step()     # Update the gradient fields\n    \n    ","metadata":{"executionCancelledAt":null,"executionTime":27982,"lastExecutedAt":1758803837723,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Training loop \nnum_epoch=10\nfor epoch in range (num_epoch):\n    model.train()    # for training the model\n    optimizer.zero_grad()    # making the gradient zero for the start\n    outputs = model(x_train_tensor)     # Forward pass: compute the output of the model\n    loss = criterion(outputs, y_train_tensor)    # the difference between the predicted and observed y value\n    loss.backward()    # Backward pass to compute new gradients for the layers. Computes the contribution of each parameter to the loss\n    optimizer.step()     # Update the gradient fields\n    \n    "},"cell_type":"code","id":"3580e2ee-bd21-4754-aa25-9ef9b58a83c1","outputs":[],"execution_count":35},{"source":"# Evaluation of the model\nmodel.eval()\nwith torch.no_grad():\n    y_train_pred = model(x_train_tensor).round()\n    y_test_pred = model(x_test_tensor).round()\n    y_val_pred = model(x_val_tensor).round()\n\n# Calculating accuracy of the model with torchmetrics\nacc = Accuracy(task = \"binary\")\nacc_train = acc(y_train_pred,y_train_tensor)\nacc_test = acc(y_test_pred, y_test_tensor)\nacc_val = acc(y_val_pred, y_val_tensor)\n\n# convert to int or float\ntrain_accuracy = acc_train.item()\ntest_accuracy = acc_test.item()\nval_accuracy = acc_val.item()\n\nprint(\"Training accuracy: {0}\".format(train_accuracy))\nprint(\"Validation accuracy: {0}\".format(val_accuracy))\nprint(\"Testing accuracy: {0}\".format(test_accuracy))\n\n","metadata":{"executionCancelledAt":null,"executionTime":1444,"lastExecutedAt":1758803839167,"lastExecutedByKernel":"ddece3ef-bc10-455f-a13a-69d0e862ac92","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Evaluation of the model\nmodel.eval()\nwith torch.no_grad():\n    y_train_pred = model(x_train_tensor).round()\n    y_test_pred = model(x_test_tensor).round()\n    y_val_pred = model(x_val_tensor).round()\n\n# Calculating accuracy of the model with torchmetrics\nacc = Accuracy(task = \"binary\")\nacc_train = acc(y_train_pred,y_train_tensor)\nacc_test = acc(y_test_pred, y_test_tensor)\nacc_val = acc(y_val_pred, y_val_tensor)\n\n# convert to int or float\ntrain_accuracy = acc_train.item()\ntest_accuracy = acc_test.item()\nval_accuracy = acc_val.item()\n\nprint(\"Training accuracy: {0}\".format(train_accuracy))\nprint(\"Validation accuracy: {0}\".format(val_accuracy))\nprint(\"Testing accuracy: {0}\".format(test_accuracy))\n\n","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"cb74f713-1e38-4928-a052-7c68a78ca270","outputs":[{"output_type":"stream","name":"stdout","text":"Training accuracy: 0.9957845211029053\nValidation accuracy: 0.9989045858383179\nTesting accuracy: 0.9439319968223572\n"}],"execution_count":36}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (User venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}